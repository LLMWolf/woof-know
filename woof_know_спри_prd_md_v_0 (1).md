# WOOF-KNOW — СПРИ: Product Requirements Document (PRD)

**Версия:** v0.1 (MVP)  
**Дата:** 28.09.2025  
**Инициатор:** Ортедос (Серый Волк)  
**Продукт:** WOOF-KNOW — СПРИ (Система Поиска Релевантной Информации)

---

## 1. Введение
**Продуктовое видение.** WOOF-KNOW — локально-ориентированный ассистент вопросов-ответов по Markdown-хранилищам (в первую очередь Obsidian), который использует **граф ссылок** и **иерархическую суммаризацию** для компоновки компактного контекста и получения ответов через API LLM. Минимум магии, максимум воспроизводимости и расширяемости.

**Цель MVP.** Реализовать рабочий конвейер: индексировать vault с заметками → построить граф связей → по вопросу пользователя обойти релевантную окрестность графа (глубина D) → суммаризовать содержимое в токен-бюджет → запросить LLM по API → вернуть ответ с опциональными ссылками/якорями на включённые заметки.

**Границы версии (scope) MVP.**
- ✅ Формат: только **Markdown** (Obsidian/GitHub-подобные наборы заметок).  
- ✅ Платформа: **Python CLI + WebUI**.  
- ✅ LLM: через **API** (облако или локально, например **Ollama**).  
- ✅ Графовый обход по ссылкам/бэклинкам с ограничениями D и лимитами узлов/чанков (из `settings.json`).  
- ✅ Иерархическая суммаризация (map→reduce) для укладки в контекст.  
- ✅ Опциональный вывод списка источников (заголовки/якоря).  
- ✅ Все параметры — в `settings.json` (глубина, лимиты, пороги, эндпоинт LLM, флаги фич).  
- ⛔ Векторный/BM25, Query Expansion, LLM-судья, внешняя верификация — **после MVP**, но интерфейсы плагинов заложены.  
- ⛔ Кэширование/прогрев — **позже** (заложить возможность).  
- ⛔ Автоперевод RU↔EN — **позже** (заложить флаг).

**Глоссарий.**
- *Vault* — каталог с Markdown-заметками (Obsidian и аналоги).  
- *D* — глубина обхода по графу ссылок.  
- *СПРИ* — Система Поиска Релевантной Информации (по графу/плагинам).  
- *Claim verification* — проверка утверждений по локальным/внешним источникам (в post-MVP).  
- *Reranker* — модуль довыбора кандидатов (cross-encoder/LLM-судья; post-MVP).

---

## 2. Целевая аудитория и JTBD
**Персоны.**
1) Индивидуальный исследователь/автор (solo) — поддерживает личный Obsidian vault.  
2) Небольшая команда знаний (≤10 участников) — общая база Markdown-доков/project wiki.

**JTBD.**
- Когда мне нужно быстро ответить на вопрос по своим заметкам, я хочу, чтобы система нашла релевантные разделы через связи и собрала краткий контекст для LLM, чтобы получить точный, ссылаемый (при необходимости) ответ без ручного поиска.

---

## 3. Цели и метрики
**Операционные цели (MVP-ориентиры):**
- **P95 латентность** (без внешней верификации): ≤ **7–10 с**.  
- **Управление релевантностью:** порог cosine по умолчанию **0.8** (настраивается).  
- **Доля «нет ответа»** (когда count кандидатов ≥ threshold = 0): ≤ **20%** на отобранном наборе тестов.  
- **Пользовательская оценка** (WebUI thumbs up/down): net-positive ≥ **+30 п.п.**

**Метрики качества (без офлайн-разметки на старте):**
- **Hit-rate@k по ссылочным ответам** (если включён показ источников): ≥ **0.7**.  
- **Доля ответов со ссылками** (при включённой опции): ≥ **0.6**.  
- **Доля запросов с 0 кандидатов ≥ threshold**: отслеживать, стремиться к снижению со временем.  
- *Примечание:* полноценные офлайн-эвалюации (эталонный Q&A набор 20–50 шт.) запланированы после R0.1.

---

## 4. Проблемы → решения (PR/FAQ, ≥6 вопросов)
**Q1. Зачем ещё одна RAG-система?**  
**A.** Мы эксплуатируем граф ссылок Obsidian как первичный сигнал, сокращая шум и снижая зависимость от тяжёлых эмбеддингов в MVP.

**Q2. Где работает LLM?**  
**A.** Через API — не важно, локально или в облаке. В MVP рекомендуем локальный **Ollama** или любой совместимый эндпоинт.

**Q3. Приватность?**  
**A.** По умолчанию контент наружу не уходит. Есть тумблер `allow_external_context` в `settings.json`. Защищённый режим предусмотрен архитектурно, но не реализуется в MVP.

**Q4. Нужно ли всегда показывать ссылки?**  
**A.** Нет. Это опция `show_sources`. Включите — получите список включённых заметок/заголовков.

**Q5. Как выбрать глубину/лимиты?**  
**A.** В `settings.json`: `depth`, `max_nodes`, `max_chunks`, `chunk_tokens_*`, `relevance_threshold`. Возможна горячая перезагрузка конфигурации (post-MVP).

**Q6. Как обрабатывать многоязычие?**  
**A.** Стратегия RU→EN→RU (перевод запрос/ответ) даст выигрыш качества; в MVP выключено (`features.translation=false`).

**Q7. Верификация утверждений?**  
**A.** В MVP — нет. Позже: указать источник/БД в конфиге и включить `features.verification`.

**Q8. Модульность и плагины?**  
**A.** Да: `ParserPlugin`, `RetrieverPlugin`, `RerankerPlugin`, `VerifierPlugin`. Контракты описаны и стабильны для сторонних разработчиков.

---

## 5. Сценарии и User Stories (INVEST) + Acceptance Criteria (Gherkin)

### US-1 — CLI-вопрос
**Как пользователь CLI,** хочу задать вопрос и получить ответ, собранный по графу связанных заметок.
```
Scenario: Ответ из графа
  Given настроен settings.json с D и лимитами
  And индекс графа построен
  When я запускаю "woof ask 'Как настроить X?'"
  Then система обходит граф до глубины D
  And суммаризует отобранные узлы в единый контекст
  And отправляет промпт в LLM API
  And показывает ответ
  And (если включено) выводит список включённых заметок с якорями
```

### US-2 — Управление параметрами без правки кода
**Как администратор,** хочу менять пороги/лимиты/эндпоинт в `settings.json`.
```
Scenario: Переопределение настроек
  Given существует settings.json
  When я меняю depth/max_nodes/relevance_threshold и endpoint
  Then следующий запрос использует новые значения
  And система логирует применённую конфигурацию
```

### US-3 — Показ релевантности и «не знаю»
**Как пользователь WebUI,** хочу видеть, сколько фрагментов найдено и их оценки.
```
Scenario: Отчёт о релевантности
  Given выполнен поиск по вопросу
  When система формирует ответ
  Then отображается count фрагментов с score ≥ threshold
  And если count = 0, показывается статус "нет ответа"
```

### US-4 — Подключение парсера как плагина
**Как разработчик,** хочу реализовать новый парсер без правок ядра.
```
Scenario: Подключение ParserPlugin
  Given опубликован контракт Plugin API
  When я реализую класс ParserPlugin и регистрирую его
  Then новые форматы индексируются без изменения ядра
```

### US-5 — Индексация vault
**Как пользователь,** хочу быстро построить/перестроить индекс графа.
```
Scenario: Индексация
  Given задан vault_path в settings.json
  When я запускаю "woof index"
  Then система парсит Markdown, строит граф, сохраняет индекс
  And сообщает краткую статистику (узлы/рёбра/время)
```

### US-6 — Опциональные ссылки на источники
**Как пользователь,** хочу включать/выключать список источников.
```
Scenario: Тумблер источников
  Given show_sources=true в settings.json
  When я задаю вопрос
  Then вместе с ответом показывается перечень заметок/якорей
  And при show_sources=false источники скрыты
```

---

## 6. Функциональные требования
**Индексация (Markdown-only, MVP):**
- Парсинг Markdown (включая front-matter, wiki-links, бэклинки, теги).  
- Построение графа (узлы: заметка/заголовок; рёбра: ссылки/теги/бэклинки).  
- Устойчивость к циклам; лимиты по D, количеству узлов и чанков.

**Сбор контекста:**
- Обход окрестности графа по D, близость/вес связей.  
- Иерархическая суммаризация (map→reduce) узлов/фрагментов.  
- Компоновка в токен-бюджет модели (с учётом `max_tokens`).

**Ответ:**
- Вызов LLM API (endpoint/модель/ключ из настроек; поддержка локальной Ollama).  
- Опциональный вывод списка источников (title → anchor).  
- Показ count найденных фрагментов и их оценок; если count=0 — статус «нет ответа».

**Конфигурация:**
- `settings.json` — единый источник параметров (см. Приложение B).  
- Валидация настроек и команда `woof config test` (R0.3).

**Интерфейсы:**
- **CLI**: `woof index`, `woof ask <query>`, `woof reindex`, `woof config test`.  
- **WebUI**: форма вопроса, индикаторы релевантности (count/threshold), опциональные источники.

**Плагины (заложить):**
- `ParserPlugin`, `RetrieverPlugin` (заглушка), `RerankerPlugin` (заглушка), `VerifierPlugin` (заглушка).

---

## 7. Нефункциональные требования
- **Платформа:** Python 3.11+, кроссплатформенность (Windows/macOS/Linux).  
- **Производительность:** P95 ≤ 7–10 с (без внешней верификации).  
- **Приватность:** по умолчанию `allow_external_context=false`; явный тумблер.  
- **Логирование:** на старте — debug в консоль; позже — структурированное логирование/метрики.  
- **Расширяемость:** стабильные контрактные интерфейсы для плагинов; отдельная документация.  
- **Надёжность:** обработка циклов, ограничение «взрывного» обхода, graceful degradation при превышении лимитов.  
- **Масштабируемость:** LLM локально/по API — без изменений ядра.

---

## 8. Приоритизация (MoSCoW, RICE)
### MoSCoW (MVP)
- **Must:** MD-индексация; граф-обход (D, лимиты); суммаризация; LLM API; CLI; WebUI (минимум); `settings.json`; опциональные источники.  
- **Should:** валидатор настроек; пример плагина-парсера; кэш графа (базовый); `config test`.  
- **Could:** горячая перезагрузка настроек; кэш часто посещаемых узлов; базовые пресеты моделей.  
- **Won’t:** QE/BM25/векторный ретривер; cross-encoder/LLM-судья; внешняя верификация; автоперевод — до V1.1.

### RICE (для ключевых элементов MVP)
Формула: **RICE = Reach × Impact × Confidence / Effort** (шкалы: 1–5; Effort — чел.-нед. при 2 ч/нед). Числа — ориентиры для планирования.

| Фича | Reach | Impact | Confidence | Effort | RICE | Комментарий |
|---|---:|---:|---:|---:|---:|---|
| Граф-обход + суммаризация | 4 | 5 | 0.8 | 3 | **5.3** | Ядро ценности |
| CLI команды (index/ask) | 5 | 4 | 0.9 | 2 | **9.0** | Быстрый value |
| WebUI (минимум) | 4 | 4 | 0.7 | 3 | **3.7** | Базовый UX |
| Settings.json + валидация | 5 | 3 | 0.9 | 1 | **13.5** | Управляемость |
| Вывод источников/якорей | 4 | 3 | 0.8 | 1 | **9.6** | Доверие |
| API плагинов (скелет) | 4 | 4 | 0.6 | 3 | **3.2** | Будущая расширяемость |
| Кэш графа | 3 | 3 | 0.7 | 2 | **3.15** | Производительность |

*Источник чисел:* экспертная оценка; подлежит уточнению после R0.1.

---

## 9. MVP и релизные срезы
**R0.1 — CLI-ядро**  
- Индексация Markdown, граф-билдер, обход D, суммаризация.  
- `settings.json`, CLI (`index`, `ask`).  
- Вывод count/threshold, опциональные источники.  
- README: архитектура, запуск, контракт плагинов (черновик).

**R0.2 — WebUI (минимум)**  
- Форма вопроса, отображение count/threshold, список источников (если включено).  
- Страница «Настройки» (read-only из `settings.json`).

**R0.3 — Качество/удобства**  
- Валидатор настроек и `woof config test`.  
- Кэш графа (файл/SQLite).  
- Пример `ParserPlugin` вне репозитория.

**Backlog (V1.1+)**  
- Cross-encoder rerank, QE/BM25/векторный ретривер.  
- Автоперевод (RU↔EN).  
- Внешняя верификация (подключаемые БД + документация контракта).  
- Горячая перезагрузка конфигурации.  
- Расширенные метрики/дашборды.

---

## 10. План валидации
- **Smoke (R0.1):** 10–20 ручных запросов владельца vault; проверка, что среди включённых узлов присутствуют ожидаемые (manual hit-rate).  
- **Evals (после R0.1):** собрать 20–50 пар Q→A; считать hit-rate@k, долю «нет ответа», долю ответов со ссылками; фиксировать P95 латентность.  
- **UX-сигналы:** thumbs up/down в WebUI; журнал «ложных срабатываний/пропусков».

---

## 11. Риски и допущения
- **Недостаточный сигнал графа** (мало ссылок/бэклинков) → заниженный recall. Контрмера: добавить ретриверы (QE/BM25/векторный) в V1.1.
- **Токен-бюджет** ограничивает полноту → агрессивная суммаризация может потерять нюансы. Контрмера: адаптивный packer, приоритет ближних узлов.
- **Минимальные ресурсы времени** (2 ч/нед) → сроки календарно растягиваются. Контрмера: узкий MVP, RICE-приоритизация.
- **Нет офлайн-эталона** на старте → сложнее измерять прогресс. Контрмера: собрать набор после R0.1.

---

## 12. Зависимости
- **Язык/рантайм:** Python 3.11+.  
- **WebUI backend:** FastAPI/uvicorn (или Streamlit/Gradio как быстрый старт).  
- **Markdown:** markdown-it-py / mistune, front-matter (PyYAML), парсер wiki-links.  
- **LLM:** API провайдера или локальный **Ollama**; HTTP-клиент, таймауты/ретраи.  
- **(Позже)** Embeddings/cross-encoder, хранилище кэша (SQLite/Parquet).

---

## 13. Открытые вопросы
1) Финальные KPI и эталонный набор 20–50 Q&A (собрать после R0.1).  
2) Горячая перезагрузка `settings.json` — нужна ли в ближайших релизах?  
3) Формат хранения графа и кэша: файл JSON/Parquet/SQLite?  
4) Требования к логам/аудиту (после ухода от консоли).  
5) Экспорт ответов/контекста обратно в vault — нужен ли?

---

## 14. Приложения

### A. Мини-архитектура (слои)
```
Ingest (Markdown Parser)
  → Graph Builder (узлы/рёбра, бэклинки)
  → Traversal (D, лимиты, защита от циклов)
  → Summarizer (map→reduce, токен-бюджет)
  → Context Packer (приоритет ближних узлов)
  → LLM Client (API/Ollama)
  → Presenter (CLI/WebUI; списки источников, count/threshold)

Плагины (контракты): ParserPlugin, RetrieverPlugin, RerankerPlugin, VerifierPlugin
```

### B. Пример `settings.json` (MVP)
```json
{
  "vault_path": "./vault",
  "depth": 2,
  "max_nodes": 200,
  "max_chunks": 1500,
  "chunk_tokens_min": 400,
  "chunk_tokens_max": 700,
  "relevance_threshold": 0.8,
  "show_sources": true,
  "allow_external_context": false,

  "llm": {
    "provider": "ollama",
    "endpoint": "http://localhost:11434/v1/chat/completions",
    "model": "llama3.1:8b",
    "max_tokens": 1024,
    "temperature": 0.2,
    "timeout_s": 60
  },

  "features": {
    "webui": true,
    "translation": false,
    "verification": false,
    "reranker": false
  }
}
```

### C. Контракты плагинов (черновик, стабильный для MVP)
```python
# parsers.py
class ParserPlugin:
    """Вход: путь к файлу. Выход: список узлов с полями:
    id, title, text, links (out), backlinks (in), tags, anchors.
    """
    name = "markdown"
    def can_handle(self, path: str) -> bool: ...
    def parse(self, path: str) -> list[dict]: ...

# retrievers.py (post-MVP)
class RetrieverPlugin:
    """Вход: query, budget, graph → Выход: ranked passages."""
    name = "graph-first"
    def retrieve(self, query: str, graph, settings) -> list[dict]: ...

# rerankers.py (post-MVP)
class RerankerPlugin:
    name = "cross-encoder"
    def rerank(self, passages: list[dict], query: str) -> list[dict]: ...

# verifiers.py (post-MVP)
class VerifierPlugin:
    """Claim verification c конфигом источника/БД."""
    name = "wiki-db"
    def verify(self, claims: list[str]) -> list[dict]: ...
```

### D. README (скелет)
- Цель и возможности (что умеет MVP; что будет дальше).  
- Архитектура (слои, диаграмма).  
- Требования/установка.  
- `settings.json`: параметры и примеры.  
- CLI-команды: `woof index`, `woof ask`, `woof reindex`, `woof config test`.  
- WebUI: запуск, поля/элементы, индикаторы.  
- Plugin API: как написать свой ParserPlugin (минимальный пример).  
- Ограничения MVP и roadmap.

### E. Definition of Ready / Definition of Done
**DoR (MVP):**
- Доступен vault; корректно заполнен `settings.json`; LLM endpoint отвечает; согласованы depth/лимиты; определён набор тестовых вопросов.

**DoD (MVP):**
- `woof index` и `woof ask` работают на тестовом vault.  
- WebUI показывает ответ, count/threshold, опциональные источники.  
- README и краткая документация Plugin API опубликованы.  
- Смоук-набор сценариев проходит (см. раздел 10).

### F. Мини-дорожная карта (1–3 релиза)
- **R0.1:** CLI ядро, суммаризация, настройки, базовые логи (консоль).  
- **R0.2:** WebUI минимум, отображение источников, thumbs up/down.  
- **R0.3:** Валидатор настроек, кэш графа, пример ParserPlugin.  
- **V1.1+:** QE/BM25/векторный ретривер, cross-encoder rerank, RU↔EN перевод, внешняя верификация (подключаемые БД + документация).

### G. Mini‑backlog (ориентир)
- **Сегодня:** каркас CLI (`index`, `ask`), парсер Markdown, граф-билдер.  
- **Эта неделя:** суммаризация map→reduce, интеграция LLM API (Ollama), `settings.json`.  
- **Бэклог:** WebUI, кэш графа, валидация конфигурации, примеры плагинов, автоперевод, альтернативные ретриверы, верификация.

### H. Передача (handoff‑инструкции)
- **BA:** согласовать KPI/метрики; подготовить 20–50 Q&A после R0.1; определить критерии «полезного ответа».  
- **UX:** спроектировать WebUI (форма вопроса, индикаторы count/threshold, тумблеры show_sources/allow_external_context, thumbs up/down).  
- **Архитектор:** утвердить формат графа и хранилища (JSON/SQLite/Parquet), контракты плагинов, стратегию кэша.  
- **QA:** Gherkin-тесты (раздел 5), проверка лимитов/циклов, измерение P95, негативные сценарии (0 кандидатов).  
- **DevOps:** шаблон `.env`, запуск Ollama/провайдера LLM, таймауты/ретраи, профили конфигурации.  
- **Security (по мере роста):** политика вывоза контента, аудит флагов настроек, маскирование секретов.

---

## 15. Открытые вопросы (для следующей сессии)
1) Минимальный эталон Q&A (20–50 пар) и целевые KPI на его базе.  
2) Требуется ли горячая перезагрузка `settings.json` в R0.2?  
3) Выбор формата кэша (JSON vs SQLite) и порогов суммаризации по умолчанию.  
4) Нужен ли экспорт ответов/контекста обратно в vault (новая заметка «Answers/…»)?

